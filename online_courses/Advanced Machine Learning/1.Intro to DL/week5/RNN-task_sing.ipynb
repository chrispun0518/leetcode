{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05064b9390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = set('#')\n",
    "for x in names:\n",
    "    tokens = tokens.union(set(x))  ### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {x : tokens.index(x) for x in tokens} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[16 43 51 53  7 53  2 28 15]\n",
      " [16 32 28 48  4  3 15 15 15]\n",
      " [16 13  4 18 33 33 18  2 15]\n",
      " [16 32 18 48 47 53 46 46  2]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb,h_t]) ### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04f459be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Forli\n",
      " Slalkee\n",
      " Luaa\n",
      " Viona\n",
      " Sorluroa\n",
      " Gorce\n",
      " Jergara\n",
      " Lanroro\n",
      " Lhwfan\n",
      " Aonarlo\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpan\n",
      " Trumpiran\n",
      " Trumpie\n",
      " Trumpelne\n",
      " Trumpana\n",
      " Trumpen\n",
      " Trumpavah\n",
      " Trumptin\n",
      " Trumparma\n",
      " Trumpann\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"SxtN9JPN9tG2Kt8L\"\n",
    "COURSERA_EMAIL = \"chrispun0518@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeeafde8a534dd688cd020aae6d81a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
